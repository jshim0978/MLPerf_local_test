# Official MLCommons MLPerf Benchmark Container
# Provides official, submission-comparable results for Llama-3.1-8B
FROM nvcr.io/nvidia/pytorch:24.07-py3

SHELL ["/bin/bash", "-c"]

# Environment setup
ENV LC_ALL=C.UTF-8
ENV LANG=C.UTF-8
ENV DEBIAN_FRONTEND=noninteractive
ENV VLLM_WORKER_MULTIPROC_METHOD=spawn
ENV PYTHONPATH=/app:/app/official_mlperf_benchmark

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    git \
    curl \
    wget \
    ca-certificates \
    python3-dev \
    python3-pip \
    rsync \
    && rm -rf /var/lib/apt/lists/*

# Create working directory
WORKDIR /app

# Copy requirements and install dependencies
COPY requirements.txt .
RUN pip3 install --upgrade pip setuptools wheel
RUN pip3 install -r requirements.txt

# Copy official MLPerf benchmark
COPY official_mlperf_benchmark/ ./official_mlperf_benchmark/

# Install MLPerf loadgen from official source
WORKDIR /app/official_mlperf_benchmark/loadgen
RUN pip3 install pybind11
RUN python3 setup.py install

# Install official benchmark requirements
WORKDIR /app/official_mlperf_benchmark
RUN pip3 install -r requirements.txt

# Copy automation scripts
WORKDIR /app
COPY run_official_benchmark.py .

# Create necessary directories
RUN mkdir -p /app/results /app/reports /app/dataset /app/logs

# Set proper permissions
RUN chmod +x run_official_benchmark.py

# Default environment variables
ENV HF_TOKEN=""
ENV SAMPLES=100
ENV ACCURACY=true
ENV MODEL_NAME="meta-llama/Llama-3.1-8B-Instruct"
ENV OUTPUT_DIR="/app/results"

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD python3 -c "import torch; print('PyTorch:', torch.__version__); print('CUDA available:', torch.cuda.is_available()); import mlperf_loadgen as lg; print('MLPerf LoadGen version:', lg.__version__)"

# Default command - run official benchmark
CMD ["python3", "run_official_benchmark.py", "--samples", "100"]

# Labels for metadata
LABEL org.opencontainers.image.title="Official MLCommons MLPerf Benchmark"
LABEL org.opencontainers.image.description="Official MLCommons inference benchmark for Llama-3.1-8B with automated reporting"
LABEL org.opencontainers.image.version="1.0"
LABEL org.opencontainers.image.vendor="MLCommons"