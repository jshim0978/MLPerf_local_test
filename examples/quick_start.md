# Quick Start Guide

**For Junior Developers: How to run MLPerf benchmarks in 3 simple steps**

## ğŸ¯ What This Project Does
This project runs AI model benchmarks across multiple GPUs to measure performance and accuracy.

## ğŸ“ Project Structure (Simple!)
```
mlperf-distributed/
â”œâ”€â”€ bin/                    # â† Run these scripts!
â”‚   â”œâ”€â”€ run_single_benchmark.py    # Test one GPU
â”‚   â””â”€â”€ run_parallel_benchmark.py  # Test both GPUs
â”œâ”€â”€ tools/                  # â† Analyze results
â”‚   â”œâ”€â”€ analyze_results.py         # Generate performance analysis
â”‚   â””â”€â”€ generate_charts.py         # Create visual charts
â”œâ”€â”€ scripts/                # â† Setup files
â”‚   â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile                 # Container setup
â”‚   â””â”€â”€ run_benchmarks.sh          # Basic runner
â”œâ”€â”€ docs/                   # â† Read for details
â”‚   â”œâ”€â”€ README.md                  # Full documentation
â”‚   â””â”€â”€ CLAUDE.md                  # Development notes
â”œâ”€â”€ examples/               # â† You are here!
â””â”€â”€ reports/                # â† Results appear here
```

## ğŸš€ 3-Step Quick Start

### Step 1: Run a Simple Test
```bash
# Test one GPU (takes ~10 minutes for 100 samples)
python3 bin/run_single_benchmark.py --node jw2 --samples 100
```

### Step 2: Run Parallel Test
```bash
# Test both GPUs simultaneously (faster!)
python3 bin/run_parallel_benchmark.py
```

### Step 3: See Your Results
```bash
# Generate charts and analysis
python3 tools/analyze_results.py
python3 tools/generate_charts.py --results-dir reports/

# View results
ls reports/          # See result files
ls reports/charts/   # See performance charts
```

## ğŸ“Š Understanding Results

**Performance Files:**
- `jw2_performance.txt` - GPU 2 benchmark results
- `jw3_performance.txt` - GPU 3 benchmark results  
- `*.json` - Accuracy validation data

**Charts:**
- `performance_analysis.png` - Complete performance breakdown
- `scaling_analysis.png` - How well multiple GPUs work together
- `throughput_comparison.png` - Speed comparison

## ğŸ¯ Real Results You Can Expect
- **Single GPU**: ~0.2 samples/second (20.6 hours for full dataset)
- **Parallel GPUs**: ~0.36 samples/second (10.4 hours for full dataset)
- **Speedup**: 4.3x faster with parallel processing!

## ğŸ†˜ Need Help?
1. Check `docs/README.md` for full documentation
2. Look at result files in `reports/` directory
3. Run with smaller `--samples 10` for quick tests

**That's it! You're now benchmarking AI models like a pro! ğŸ‰**