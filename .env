# MLPerf Environment Configuration
# Local testing configuration

# HuggingFace Token 
HF_TOKEN=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

# User Configuration
MLPERF_USERNAME=jungwooshim
MLPERF_REMOTE_DIR=~/MLPerf_local_test

# Node IP Addresses (set to localhost for local testing)
JW1_IP=localhost
JW2_IP=localhost  
JW3_IP=localhost

# Benchmark Configuration
MAX_TOKENS=64
SERVER_TARGET_QPS=1.0
OFFLINE_TARGET_QPS=10.0

# Optional: CUDA Device Selection
CUDA_VISIBLE_DEVICES=0

# Model Configuration
MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
BATCH_SIZE=1
DTYPE=float16
TENSOR_PARALLEL_SIZE=1