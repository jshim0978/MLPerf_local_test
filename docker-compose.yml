version: '3.8'

services:
  mlperf-benchmark:
    build: .
    image: mlperf-universal:latest
    container_name: mlperf-benchmark
    environment:
      - HF_TOKEN=your-huggingface-token-here
      - SAMPLES=13368
      - ACCURACY=false
      - NODE_NAME=local
      - MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
      - OUTPUT_DIR=/app/results
    volumes:
      - ./results:/app/results
      - ./reports:/app/reports
      - huggingface-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: ["python3", "bin/run_benchmark.py", "--samples", "13368"]

  mlperf-accuracy:
    build: .
    image: mlperf-universal:latest
    container_name: mlperf-accuracy
    environment:
      - HF_TOKEN=your-huggingface-token-here
      - SAMPLES=13368
      - ACCURACY=true
      - NODE_NAME=local
      - MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
      - OUTPUT_DIR=/app/results
    volumes:
      - ./results:/app/results
      - ./reports:/app/reports
      - huggingface-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: ["python3", "bin/run_benchmark.py", "--samples", "13368", "--accuracy"]
    profiles:
      - accuracy

  mlperf-distributed:
    build: .
    image: mlperf-universal:latest
    container_name: mlperf-distributed-${NODE_ID:-1}
    environment:
      - HF_TOKEN=your-huggingface-token-here
      - SAMPLES=13368
      - ACCURACY=false
      - NODE_NAME=node-${NODE_ID:-1}
      - MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
      - OUTPUT_DIR=/app/results
      - TENSOR_PARALLEL_SIZE=2
    volumes:
      - ./results:/app/results
      - ./reports:/app/reports
      - huggingface-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: ["python3", "bin/run_distributed_benchmark.py", "--samples", "13368", "--tensor-parallel-size", "2"]
    profiles:
      - distributed

volumes:
  huggingface-cache:
    driver: local