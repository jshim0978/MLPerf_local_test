# Llama-3.1-8B Benchmark Results

**Date:** July 15, 2025  
**Model:** Llama-3.1-8B-Instruct  
**Hardware:** NVIDIA A30 + Intel Xeon Gold 6248R  

## Results Summary

| Metric | Result |
|--------|--------|
| **Throughput** | 1.02 samples/second |
| **Token Speed** | 34.9 tokens/second |
| **Response Time** | 984ms average |
| **GPU Memory Used** | 14.99 GB (62% of 24GB) |
| **Success Rate** | 100% (10/10 samples) |

## System Specs

- **GPU:** NVIDIA A30 (24GB VRAM)
- **CPU:** Intel Xeon Gold 6248R (96 cores)
- **RAM:** 1.5TB
- **OS:** Ubuntu 22.04
- **Model Size:** 8 billion parameters

## Performance Rating

âœ… **GOOD** - Suitable for production use
- Fast enough for real-time applications
- Stable performance 
- Efficient memory usage
- Room for optimization

## Bottom Line

The Llama-3.1-8B model runs well on A30 hardware with good performance for most applications. The system can handle real-time inference with sub-second response times.