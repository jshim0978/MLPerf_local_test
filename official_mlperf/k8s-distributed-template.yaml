# MLPerf Distributed Kubernetes Template
# Use this as a base for distributed multi-GPU benchmarking

apiVersion: batch/v1
kind: Job
metadata:
  name: mlperf-distributed-TIMESTAMP
  namespace: mlperf
spec:
  parallelism: 2  # Number of GPU workers
  completions: 2
  template:
    metadata:
      labels:
        app: mlperf-distributed
        job-id: TIMESTAMP
    spec:
      restartPolicy: Never
      containers:
      - name: mlperf-worker
        image: mlperf/inference:latest
        resources:
          requests:
            nvidia.com/gpu: 1
            memory: 16Gi
            cpu: 4
          limits:
            nvidia.com/gpu: 1
            memory: 32Gi
            cpu: 8
        env:
        - name: SAMPLES
          value: "100"
        - name: ACCURACY
          value: "false"
        - name: NODE_RANK
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: WORLD_SIZE
          value: "2"
        # DeepSpeed/NCCL configuration
        - name: NCCL_DEBUG
          value: "INFO"
        - name: NCCL_SOCKET_IFNAME
          value: "eth0"
        - name: NCCL_IB_DISABLE
          value: "1"
        - name: MASTER_ADDR
          value: "mlperf-distributed-TIMESTAMP-0"
        - name: MASTER_PORT
          value: "29500"
        command: ["python3"]
        args:
        - "/workspace/main.py"
        - "--scenario"
        - "Server"
        - "--model-path" 
        - "meta-llama/Llama-3.1-8B-Instruct"
        - "--batch-size"
        - "1"
        - "--dtype"
        - "float16"
        - "--total-sample-count"
        - "50"  # Distribute samples across workers
        - "--dataset-path"
        - "cnn_eval.json"
        - "--output-log-dir"
        - "/workspace/results"
        - "--tensor-parallel-size"
        - "1"
        - "--vllm"
        - "--user-conf"
        - "user.conf"
        volumeMounts:
        - name: results-volume
          mountPath: /workspace/results
      volumes:
      - name: results-volume
        persistentVolumeClaim:
          claimName: mlperf-results-TIMESTAMP

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mlperf-results-TIMESTAMP
  namespace: mlperf
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 10Gi