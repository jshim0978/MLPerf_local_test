#!/bin/bash
#
# MLPerf Test Benchmark Runner - Quick Tests with 20 samples
# Online scenarios only (Server) on jw2, jw3, and multi-GPU
#

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RESULTS_DIR="/home/jungwooshim/results"

echo "ğŸ§ª MLPerf Test Benchmark Runner (Server Scenario)"
echo "================================================="
echo "Using 20 samples for quick testing (~3-5 minutes each)"
echo "Testing online scenarios only:"
echo "  â€¢ Single GPU jw2 - Server scenario" 
echo "  â€¢ Single GPU jw3 - Server scenario"
echo "  â€¢ Multi-GPU distributed - Server scenario"
echo ""

# Create results directory
mkdir -p "$RESULTS_DIR"

function run_test_single_gpu_jw2() {
    echo "ğŸ§ª Running TEST Single GPU Server Benchmark on jw2..."
    kubectl delete job mlperf-test-single-gpu-jw2-server --ignore-not-found=true
    kubectl apply -f "$SCRIPT_DIR/k8s-test-single-gpu-jw2-server.yaml"
    
    echo "â³ Waiting for jw2 test benchmark to complete..."
    kubectl wait --for=condition=complete --timeout=900s job/mlperf-test-single-gpu-jw2-server
    
    echo "âœ… jw2 test benchmark completed!"
    kubectl logs job/mlperf-test-single-gpu-jw2-server | tail -20
}

function run_test_single_gpu_jw3() {
    echo "ğŸ§ª Running TEST Single GPU Server Benchmark on jw3..."
    kubectl delete job mlperf-test-single-gpu-jw3-server --ignore-not-found=true
    kubectl apply -f "$SCRIPT_DIR/k8s-test-single-gpu-jw3-server.yaml"
    
    echo "â³ Waiting for jw3 test benchmark to complete..."
    kubectl wait --for=condition=complete --timeout=900s job/mlperf-test-single-gpu-jw3-server
    
    echo "âœ… jw3 test benchmark completed!"
    kubectl logs job/mlperf-test-single-gpu-jw3-server | tail -20
}

function run_test_multi_gpu_distributed() {
    echo "ğŸ§ª Running TEST Multi-GPU Distributed Server Benchmark..."
    kubectl delete job mlperf-test-multi-gpu-server --ignore-not-found=true
    kubectl apply -f "$SCRIPT_DIR/k8s-test-multi-gpu-server.yaml"
    
    echo "â³ Waiting for multi-GPU test benchmark to complete..."
    kubectl wait --for=condition=complete --timeout=900s job/mlperf-test-multi-gpu-server
    
    echo "âœ… Multi-GPU test benchmark completed!"
    kubectl logs job/mlperf-test-multi-gpu-server | tail -20
}

function generate_test_report() {
    echo "ğŸ“Š Generating Test MLPerf Report..."
    
    # Create report using test results
    cat > "$RESULTS_DIR/test_mlperf_report.md" << EOF
# MLPerf Test Results - Server Scenario (20 samples)

Generated on: $(date)
Implementation: Official MLCommons Reference
Dataset: CNN DailyMail (20 test samples)
Scenario: Server (Online)

## System Configuration
- jw1 (control plane): No GPU
- jw2 (worker): 1x NVIDIA A30 GPU  
- jw3 (worker): 1x NVIDIA A30 GPU

## Test Results (20 samples each)

### Single GPU - jw2 (Server Scenario)
$(ls $RESULTS_DIR/jw2_test_server_results/ 2>/dev/null | head -10 || echo "Results pending...")

### Single GPU - jw3 (Server Scenario)  
$(ls $RESULTS_DIR/jw3_test_server_results/ 2>/dev/null | head -10 || echo "Results pending...")

### Multi-GPU Distributed (Server Scenario)
$(ls $RESULTS_DIR/multi_gpu_test_server_results/ 2>/dev/null | head -10 || echo "Results pending...")

## MLPerf Compliance (Test Mode)
- âœ… Official MLCommons loadgen
- âœ… VLLM optimization
- âœ… CNN DailyMail dataset (20 samples for testing)
- âœ… Server scenario (online inference)
- âœ… Proper token counting and reporting
- âœ… FirstTokenComplete callbacks

Generated by Official MLPerf Test Implementation
EOF
    
    echo "ğŸ“‹ Test report saved to: $RESULTS_DIR/test_mlperf_report.md"
}

function main() {
    case "${1:-all}" in
        "jw2")
            run_test_single_gpu_jw2
            ;;
        "jw3")
            run_test_single_gpu_jw3
            ;;
        "multi-gpu")
            run_test_multi_gpu_distributed
            ;;
        "all")
            echo "ğŸƒ Running all test MLPerf benchmarks..."
            run_test_single_gpu_jw2
            run_test_single_gpu_jw3  
            run_test_multi_gpu_distributed
            generate_test_report
            ;;
        "report")
            generate_test_report
            ;;
        *)
            echo "Usage: $0 [jw2|jw3|multi-gpu|all|report]"
            exit 1
            ;;
    esac
    
    echo ""
    echo "ğŸ‰ Test MLPerf benchmarks completed!"
    echo "ğŸ“ Results available in: $RESULTS_DIR"
    echo "ğŸ’¡ Each test used only 20 samples for quick validation"
}

main "$@"