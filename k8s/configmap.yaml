apiVersion: v1
kind: ConfigMap
metadata:
  name: mlperf-config
  namespace: default
data:
  # MLPerf Configuration
  SAMPLES: "13368"  # Full dataset benchmark
  ACCURACY: "false"  # Set to "true" for accuracy benchmarks
  SERVER_TARGET_QPS: "1.0"
  MAX_TOKENS: "64"
  BATCH_SIZE: "1"
  DTYPE: "float16"
  TENSOR_PARALLEL_SIZE: "1"
  
  # Model Configuration
  MODEL_NAME: "meta-llama/Llama-3.1-8B-Instruct"
  MAX_MODEL_LEN: "8192"
  GPU_MEMORY_UTILIZATION: "0.9"
  
  # Output Configuration
  OUTPUT_DIR: "/shared/results"
  REPORTS_DIR: "/shared/reports"
  
  # Node Configuration (Override these for your cluster)
  JW1_IP: "your-controller-ip"
  JW2_IP: "your-worker1-ip" 
  JW3_IP: "your-worker2-ip"
  MLPERF_USERNAME: "your-username"
  
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mlperf-scripts
  namespace: default
data:
  run-benchmark.sh: |
    #!/bin/bash
    set -e
    
    echo "üöÄ Starting MLPerf Benchmark in Kubernetes"
    echo "==========================================="
    echo "Node: ${NODE_NAME:-local}"
    echo "Samples: ${SAMPLES:-13368}"
    echo "Accuracy: ${ACCURACY:-false}"
    echo "Model: ${MODEL_NAME}"
    echo "Output: ${OUTPUT_DIR}"
    echo ""
    
    # Create output directories
    mkdir -p ${OUTPUT_DIR} ${REPORTS_DIR}
    
    # Run benchmark
    if [ "${ACCURACY}" = "true" ]; then
      echo "Running accuracy benchmark..."
      python3 bin/run_benchmark.py --samples ${SAMPLES} --accuracy
    else
      echo "Running performance benchmark..."
      python3 bin/run_benchmark.py --samples ${SAMPLES}
    fi
    
    # Generate comprehensive report
    echo "Generating comprehensive report..."
    python3 report_generator.py
    
    echo "‚úÖ Benchmark completed successfully!"
    echo "üìä Results available in: ${OUTPUT_DIR}"
    echo "üìã Reports available in: ${REPORTS_DIR}"
    
  setup-cluster.sh: |
    #!/bin/bash
    echo "üîß Setting up MLPerf cluster environment..."
    
    # Download dataset if not present
    if [ ! -f "official_mlperf/cnn_eval.json" ]; then
      echo "üì• Downloading CNN/DailyMail dataset..."
      cd official_mlperf
      python3 download_cnndm.py --n-samples ${SAMPLES:-13368}
      cd ..
    fi
    
    # Verify GPU availability
    if command -v nvidia-smi &> /dev/null; then
      echo "‚úÖ GPU Status:"
      nvidia-smi --query-gpu=name,memory.total --format=csv
    else
      echo "‚ö†Ô∏è GPU not available - CPU inference will be used"
    fi
    
    echo "‚úÖ Cluster setup complete"