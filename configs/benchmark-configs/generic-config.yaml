# Generic Hardware Configuration Template
hardware:
  type: "${HARDWARE_TYPE:-cpu}"
  model: "${HARDWARE_MODEL:-generic}"
  memory_gb: "${HARDWARE_MEMORY_GB:-16}"
  compute_capability: "${COMPUTE_CAPABILITY:-generic}"

benchmark:
  model_name: "${MODEL_NAME:-meta-llama/Llama-3.1-8B-Instruct}"
  max_tokens: "${MAX_TOKENS:-64}"
  batch_size: "${BATCH_SIZE:-1}"
  max_sequence_length: "${MAX_SEQUENCE_LENGTH:-2048}"
  
  # Configurable performance targets
  server_target_qps: "${SERVER_TARGET_QPS:-0.1}"
  server_latency_constraint_ms: "${SERVER_LATENCY_CONSTRAINT:-5000.0}"
  offline_target_qps: "${OFFLINE_TARGET_QPS:-0.5}"
  
  # Memory settings
  memory_utilization_target: "${MEMORY_UTILIZATION:-0.70}"
  tensor_parallel_size: "${TENSOR_PARALLEL_SIZE:-1}"
  pipeline_parallel_size: "${PIPELINE_PARALLEL_SIZE:-1}"

deployment:
  node_selector:
    accelerator: "${NODE_ACCELERATOR:-generic}"
  resources:
    limits:
      memory: "${MEMORY_LIMIT:-16Gi}"
      cpu: "${CPU_LIMIT:-4}"
    requests:
      memory: "${MEMORY_REQUEST:-8Gi}"
      cpu: "${CPU_REQUEST:-2}"

optimization:
  precision: "${PRECISION:-fp32}"
  enable_optimization: "${ENABLE_OPTIMIZATION:-false}"
  
adapter:
  module: "${ADAPTER_MODULE:-src.adapters.generic_adapter}"
  class: "${ADAPTER_CLASS:-GenericAdapter}"