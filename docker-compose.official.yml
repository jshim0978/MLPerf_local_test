version: '3.8'

services:
  mlperf-official-benchmark:
    build: 
      context: .
      dockerfile: Dockerfile.official
    image: mlperf-official:latest
    container_name: mlperf-official-benchmark
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - SAMPLES=100
      - MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
      - OUTPUT_DIR=/app/results
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./results:/app/results
      - ./reports:/app/reports
      - ./dataset:/app/dataset
      - huggingface-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: ["python3", "run_official_benchmark.py", "--samples", "100"]

  mlperf-official-performance:
    build: 
      context: .
      dockerfile: Dockerfile.official
    image: mlperf-official:latest
    container_name: mlperf-official-performance
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - SAMPLES=100
      - MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
      - OUTPUT_DIR=/app/results
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./results:/app/results
      - ./reports:/app/reports
      - ./dataset:/app/dataset
      - huggingface-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: ["python3", "run_official_benchmark.py", "--samples", "100", "--performance-only"]
    profiles:
      - performance

  mlperf-official-accuracy:
    build: 
      context: .
      dockerfile: Dockerfile.official
    image: mlperf-official:latest
    container_name: mlperf-official-accuracy
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - SAMPLES=100
      - MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
      - OUTPUT_DIR=/app/results
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./results:/app/results
      - ./reports:/app/reports
      - ./dataset:/app/dataset
      - huggingface-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: ["python3", "run_official_benchmark.py", "--samples", "100", "--accuracy-only"]
    profiles:
      - accuracy

volumes:
  huggingface-cache:
    driver: local